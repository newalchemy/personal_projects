{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST Data deep clustering",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4m7vlxjNcQlW7R4+RC8lm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newalchemy/personal_test/blob/main/MNIST_Data_deep_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyfHnthil2lx"
      },
      "source": [
        "#  **Deep clustering on MNIST Dataset**\n",
        "\n",
        "This notebook will do the following:    \n",
        "1.  Implement an auto-encoder on the MNIST dataset.\n",
        "2.  Perform differential k-means clustering on the bottleneck layer, with K=10\n",
        "3.  Evaluate the model and discuss the parameters tuned.\n",
        "\n",
        "The overall approach that I took was to train the auto-encoder first, use t-SNE to verify seperability of the bottleneck layer, and then run differential k-means on the encoded MNIST pictures.  I then used t-SNE to evaluate the output and clusters to further assist in the tuning of hyperparameters.  This is an assignment that I did for a course that I took in graduate school, Deep Learning and Neural Computation.\n",
        "\n",
        "## **Autoencoding and verification (Part 1/3)**\n",
        "The code below is the implementation of the autoencoder, and the encoding of the pictures using the bottleneck layer.  Additionally, t-SNE is used at the end to verify that the encoded images are separable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ghHJXwihEGq"
      },
      "source": [
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# Bookkeeping for Google Drive\n",
        "drive.mount('/content/drive');\n",
        "\n",
        "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device0)\n",
        "\n",
        "mnist_loc = '/content/drive/My Drive/MNIST_Data/';\n",
        "\n",
        "mnist_AE_out_loc = '/content/drive/My Drive/MNIST_AE_Out/';\n",
        "\n",
        "file_loc = '/content/drive/My Drive/diffKMeans_out/';\n",
        "\n",
        "tsne_loc = '/content/drive/My Drive/tSNE_Out/';\n",
        "file_loc = '/content/drive/My Drive/diffKMeans_out/';\n",
        "\n",
        "\n",
        "num_epochs = 30\n",
        "batch_size = 256\n",
        "learning_rate = 1e-3\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = MNIST(mnist_loc, transform=img_transform, download=True);\n",
        "# dataset = MNIST('C:\\\\Users\\\\timhe\\\\OneDrive\\\\Documents\\\\StatsWorkFolder\\\\CS5525\\\\MNIST', download=True);\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True);\n",
        "\n",
        "# I wish I could take credit for this autoencoder.  However, this was the first assignment of the class, and CNNs were not covered yet, so\n",
        "# the original autoencoder simply flattened the image and passed it through several fully connected layers for the encoder and decoder.\n",
        "#\n",
        "# When I revisited this, I decided that a CNN would likely provide much better performance.  \n",
        "# Instead of reinventing the wheel, I used the autoencoder from here.\n",
        "#\n",
        "# https://medium.com/dataseries/convolutional-autoencoder-in-pytorch-on-mnist-dataset-d65145c132ac\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "          nn.Conv2d(1, 8, 3, stride=2, padding=1),#15\n",
        "          nn.ReLU(True),\n",
        "          nn.Conv2d(8, 16, 3, stride=2, padding=1),#9\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.ReLU(True),\n",
        "          nn.Conv2d(16, 32, 3, stride=2, padding=0),#5     \n",
        "          nn.ReLU(True),\n",
        "          nn.Flatten(start_dim=1),\n",
        "          nn.Linear(32 * 3 * 3, 128),\n",
        "          nn.ReLU(True),\n",
        "          nn.Linear(128,4)\n",
        "        );\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "          nn.Linear(4, 128),\n",
        "          nn.ReLU(True), \n",
        "          nn.Linear(128, 3 * 3 * 32),\n",
        "          nn.ReLU(True),\n",
        "          nn.Unflatten(dim=1, unflattened_size=(32,3,3)),\n",
        "          nn.ConvTranspose2d(32,16, 3, stride=2),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.ReLU(True),\n",
        "          nn.ConvTranspose2d(16,8,3, stride=2, padding=1, output_padding=1),\n",
        "          nn.ReLU(True),\n",
        "          nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
        "        );\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x);\n",
        "        self.latent = x.clone();\n",
        "        x = self.decoder(x);\n",
        "        x = torch.sigmoid(x);\n",
        "        return x\n",
        "    \n",
        "    def getLatentLayer(self):\n",
        "        return self.latent;\n",
        "\n",
        "def add_noise(inp_tensor, noise_factor=0.3):\n",
        "    sx = inp_tensor.size();\n",
        "    out_tensor = inp_tensor + torch.normal(0, noise_factor, sx);\n",
        "    return out_tensor;\n",
        "\n",
        "model = autoencoder();\n",
        "model = model.to(device0);\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "batch_iter = 0;\n",
        "\n",
        "num_samp = 0;\n",
        "losses = [];\n",
        "for epoch in range(num_epochs):\n",
        "    for data in dataloader:\n",
        "        img, _ = data\n",
        "        img = img.to(device0);\n",
        "        # ===================forward=====================\n",
        "        output = model(img)\n",
        "        loss = criterion(output, img)\n",
        "        # ===================backward====================\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (epoch == 0): \n",
        "          sx = img.size();\n",
        "          num_samp = num_samp + sx[0];        \n",
        "    # ===================log========================\n",
        "torch.save(model.state_dict(), '{}mnist_autoencoder.pth'.format(file_loc))\n",
        "print('done creating auto-encoder!')\n",
        "\n",
        "# Create the encoded images one at a time, and save them in a pickle file in my google drive.\n",
        "dataloader_2 = DataLoader(dataset, batch_size=1, shuffle=True);\n",
        "\n",
        "images_reduced = torch.zeros(num_samp, 4);\n",
        "labels_true = torch.zeros(num_samp, 1);\n",
        "itr = 0;\n",
        "for data in dataloader_2:\n",
        "    img, label = data;\n",
        "    img = img.to(device0);\n",
        "    output = model(img);\n",
        "    img_reduced = model.getLatentLayer();\n",
        "    images_reduced[itr, :] = img_reduced;\n",
        "    labels_true[itr] = label;\n",
        "    itr = itr + 1;\n",
        "\n",
        "with open(file_loc + 'images_reduced.pickle', 'wb') as handle:\n",
        "    pickle.dump(images_reduced, handle)\n",
        "\n",
        "with open(file_loc + 'labels_true.pickle', 'wb') as handle:\n",
        "    pickle.dump(labels_true, handle)\n",
        "\n",
        "print('done encoding images!')\n",
        "\n",
        "with open(file_loc + 'images_reduced.pickle', 'rb') as handle:\n",
        "    images_reduced = pickle.load(handle)\n",
        "\n",
        "with open(file_loc + 'labels_true.pickle', 'rb') as handle:\n",
        "    labels_true = pickle.load(handle)\n",
        "\n",
        "n_components = 2;\n",
        "perplexity = 30;\n",
        "early_exaggeration = 12;\n",
        "learning_rate = 200;\n",
        "n_iter = 1000;\n",
        "n_iter_without_progress = 300;\n",
        "min_grad_norm = 1e-7;\n",
        "init='pca'\n",
        "\n",
        "tsneOut = TSNE(n_components=2).fit_transform(images_reduced.detach().numpy());\n",
        "#tsneOut = TSNE(n_components=n_components, perplexity=perplexity, early_exaggeration=early_exaggeration, \n",
        "#               learning_rate=learning_rate, n_iter=n_iter, n_iter_without_progress=n_iter_without_progress, \n",
        "#               min_grad_norm=min_grad_norm, init=init).fit_transform(images_reduced.detach().numpy());\n",
        "#tsneOut = tsnecuda.TSNE(n_components=n_components, perplexity=perplexity, learning_rate=learning_rate).fit_transform(images_reduced.detach().numpy());\n",
        "\n",
        "\n",
        "\n",
        "with open(file_loc + 'tsneOut.pickle', 'wb') as handle:\n",
        "    pickle.dump(tsneOut, handle)\n",
        "\n",
        "#with open(file_loc + 'tsneOut.pickle', 'rb') as handle:\n",
        "#    tsneOut = pickle.load(handle)\n",
        "\n",
        "label_colors = ['red', 'darkorange', 'yellow', 'darkgreen', 'cyan', 'steelblue', 'navy', 'darkviolet', 'deeppink', 'grey'];\n",
        "\n",
        "#Separate the x and y values\n",
        "xa = tsneOut[:,0];\n",
        "ya = tsneOut[:,1];\n",
        "\n",
        "f4 = plt.figure();\n",
        "f4.suptitle('t-SNE plot - latent data to 2 dimensions');\n",
        "\n",
        "for itr in range(10):\n",
        "    myColor = label_colors[itr];\n",
        "    myLabel_inxs = [i for i, val in enumerate(labels_true) if val==itr];\n",
        "\n",
        "    x_lab = xa[myLabel_inxs];\n",
        "    y_lab = ya[myLabel_inxs];\n",
        "\n",
        "    plt.scatter(x_lab, y_lab, c=myColor, axes=f4.gca(), marker='.');\n",
        "\n",
        "path = '{}{}.png'.format(tsne_loc, 'TSNE_Plot');\n",
        "f4.savefig(fname=path);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIeI8QeLVuVm"
      },
      "source": [
        "Encode all of the images into the latent layer of the auto-encoder, and save off the images in a pickle file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuXGQdwWTk3O"
      },
      "source": [
        "## **Differential K Means (Part 2/3)**\n",
        "\n",
        "Differential K means is performed by starting with K initial clusters, and then performing gradient descent to move the cluster centers to their optimal locations.  All points are assigned a label based on which cluster they are closest to.\n",
        "\n",
        "The loss function, without penalization, is defined as the following:\n",
        "\n",
        "$$ Loss = \\Sigma_x\\Sigma_kD .* W $$\n",
        "\n",
        "Where:     \n",
        "\n",
        "**D**: A *num_samples x K* matrix which contains the euclidean distance squared between each point and each cluster center.\n",
        "\n",
        "**.***:  Pointwise matrix multiplication.\n",
        "\n",
        "**W**:  A *num_samples x K* matrix which contains the probability that each point belongs in each cluster.  Each row sums to 1.  It is computed based off of the following equation:\n",
        "\n",
        "$$ W_{xc} = \\frac{exp(-D_{xc}/BANDWIDTH)}{\\Sigma_cexp(-D_{xc}/BANDWIDTH)}$$ \n",
        "\n",
        "where D is the matrix defined above, and BANDWIDTH is a hyperparameter, x is a point, and c is a cluster center.  \n",
        "\n",
        "This equation means that each entry in W is defined as the gaussian transformation of the euclidean distance squared between that point and its cluster center, normalized to the gaussian transformation between that point and all other clusters.  \n",
        "\n",
        "### **Penalization Term**\n",
        "\n",
        "I decided to introduce a penalization term in order to disincentivize the algorithm from landing on local minima where multiple cluster centers happened to be close together, since minima with clusters closer together generally results in lower accuracy scores for the output.  \n",
        "\n",
        "The penalization term is defined as:     \n",
        "\n",
        "$$ P = C*\\Sigma_{k>i\\ge 0}\\Sigma_{k>j>i}\\frac{1}{||c_i - c_j||_2^2}$$\n",
        "\n",
        "This equation means that the euclidean distance between each cluster center is squared, has its reciprocal taken, and is added together and multipled by a constant C, which is a hyperparameter.\n",
        "\n",
        "This penalization, with hyperparameter C=10, gave a 2% increase in the accuracy of the results.\n",
        "\n",
        "### **Cluster Initialization**\n",
        "The initial clusters are defined in this way:     \n",
        "\n",
        "1. Choose one of the points passed to the algorithm at random.  That is the first cluster center.\n",
        "\n",
        "2.  For each point that is not a cluster center, take the euclidean distance between itself and the current cluster centers.  Then, keep the smallest of those distances computed, and do that for each point.  The value D(x), for a given point x, will be that \"largest smallest distance\".\n",
        "\n",
        "3.  Choose the next cluster center randomly, where each point x has the probability listed below of being selected:\n",
        "\n",
        "$$ P(x) = \\frac{D(x)^2}{\\Sigma_x{D(x)^2}} $$\n",
        "\n",
        "This is the k-means++ initialization algorithm, which is currently very popular and known to produce very good results.  \n",
        "\n",
        "### **Hyperparameters**\n",
        "\n",
        "The hyperparameters for this algorithm are:     \n",
        "\n",
        "**K**:  The number of clusters, predefined by the assignment (10).\n",
        "\n",
        "**Bandwidth**:  The Bandwidth of the RBF Gaussian Kernel used to generate W.\n",
        "\n",
        "**learning_rate**: Update rate for each timestep.\n",
        "\n",
        "**num_epochs**:   How many epochs to compute the gradient for.\n",
        "\n",
        "**C**:    The weight to put on the penalization term.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWvUjpNSZr0D"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "from matplotlib import pyplot\n",
        "# from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import numpy as np\n",
        "import gc\n",
        "import logging\n",
        "import random\n",
        "\n",
        "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "drive.mount('/content/drive');\n",
        "\n",
        "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device0)\n",
        "\n",
        "mnist_loc = '/content/drive/My Drive/MNIST_Data/';\n",
        "\n",
        "file_loc = '/content/drive/My Drive/diffKMeans_out/';\n",
        "\n",
        "\n",
        "def diffKMeans(X, labels_true, K, BANDWIDTH, num_epochs, learning_rate, device):\n",
        "    \n",
        "    sx = X.size();\n",
        "    num_samples = sx[0];\n",
        "    num_dim = sx[1];\n",
        "    \n",
        "    # Initialize clusters\n",
        "    U_initialClusters = initializeKMeansPoints(X,K,device);\n",
        "    U_vals = U_initialClusters.detach_().clone();\n",
        "    cluster_centers_over_time = torch.zeros(num_epochs, K, num_dim);\n",
        "    cluster_centers_over_time[0,:,:] = U_initialClusters.detach_().clone();\n",
        "    \n",
        "    # U_vals is the variable we will be performing gradient descent on.\n",
        "    U_vals.requires_grad_(True);\n",
        "    U_vals = U_vals.to(device);\n",
        "\n",
        "\n",
        "    iters = 0;\n",
        "\n",
        "    loss_vals_over_time = [];\n",
        "    scores_over_time = [];\n",
        "    labels_over_time = torch.zeros(num_epochs, num_samples);\n",
        "    \n",
        "    iters = 0;\n",
        "    while iters < num_epochs:\n",
        "        \n",
        "        # D is a num_samples x K matrix, which contains the distance between each point and each cluster.\n",
        "        # The distance measure is euclidean distance, squared.\n",
        "        D = torch.zeros(num_samples, K, device=device);\n",
        "        for p in range(num_samples):\n",
        "            myP = X[p,:];\n",
        "            for c in range(K):\n",
        "                myC = U_vals[c,:];\n",
        "                dist = (myP - myC) ** 2;\n",
        "\n",
        "                D[p,c] = torch.sum(dist, dim=0);\n",
        "                #D[p,c] = dist.sum(dim=0);\n",
        "        \n",
        "        if (iters % 25 == 0):\n",
        "            with open('/content/drive/My Drive/diffKMeans_out/' + 'D_{}.pickle'.format(iters), 'wb') as handle:\n",
        "                D_out = D.clone();\n",
        "                D_out = D_out.to('cpu');\n",
        "                pickle.dump(D_out, handle);\n",
        "                del D_out\n",
        "        \n",
        "        # W is a num_samples x K matrix which contains, for each point, the probability that \n",
        "        # the point belongs to a specific cluster.\n",
        "        # It is a direct function of how far away each point is from the given cluster.  \n",
        "        # It uses a RBF Gaussian Kernel, then normalizes it so it turns into a set of probabilities.  \n",
        "        # Each row in the W matrix sums to 1. \n",
        "        G = torch.exp(-D/BANDWIDTH);\n",
        "        G_sum = torch.sum(G, dim=1);\n",
        "        W = torch.zeros(num_samples, K, device=device);\n",
        "\n",
        "        for l in range(K):\n",
        "            W[:,l] = G[:,l] / G_sum\n",
        "            \n",
        "            if (iters % 25 == 0):\n",
        "                with open('/content/drive/My Drive/diffKMeans_out/' + 'cluster_centers_{}.pickle'.format(iters), 'wb') as handle:\n",
        "                    cluster_clone = cluster_centers_over_time.clone();\n",
        "                    cluster_clone = cluster_clone.to('cpu');\n",
        "                    pickle.dump(cluster_clone, handle);\n",
        "                    del cluster_clone\n",
        "\n",
        "                with open('/content/drive/My Drive/diffKMeans_out/' + 'labels_over_time_{}.pickle'.format(iters), 'wb') as handle:\n",
        "                    labels_clone = labels_over_time.clone();\n",
        "                    labels_clone = labels_clone.to('cpu');\n",
        "                    pickle.dump(labels_clone, handle)\n",
        "                    del labels_clone\n",
        "\n",
        "         #This was my penalty function which was used to penalize clusters which are too close to each other.\n",
        "        P = torch.zeros(K, K);\n",
        "        for i in range(K):\n",
        "            myP = U_vals[i, :];\n",
        "            for j in range(i + 1, K):\n",
        "                curP = U_vals[j, :];\n",
        "                diff = 1/torch.sum((myP - curP) ** 2);\n",
        "                P[i,j] = diff;\n",
        "\n",
        "\n",
        "        # Performing the back propogation and gradient descent.\n",
        "        F = D * W;\n",
        "        #loss = torch.sum(torch.sum(F, dim=1), dim=0);\n",
        "        loss = torch.sum(torch.sum(F, dim=1), dim=0) + 10*torch.sum(torch.sum(P, dim=1), dim=0);\n",
        "        loss.backward();\n",
        "    \n",
        "        U_vals.data = U_vals.data - learning_rate*U_vals.grad.data/num_samples;\n",
        "\n",
        "        U_vals.grad.zero_();\n",
        "        U_vals.requires_grad_(True);\n",
        "        \n",
        "        # Bookkeeping of certain variables/information for analysis later.\n",
        "        loss_clone = loss.clone().detach_().to('cpu');\n",
        "        loss_vals_over_time.append(loss_clone);\n",
        "        \n",
        "        cluster_centers_over_time[iters,:,:] = U_vals.data.clone();\n",
        "        for ns in range(num_samples):\n",
        "            myI = W[ns,:];\n",
        "            m = torch.argmax(myI);\n",
        "            labels_over_time[iters, ns] = m.int();\n",
        "\n",
        "        labels_now = labels_over_time[iters, :];\n",
        "        score_now = cluster_acc(np.asarray(labels_true), labels_now.int().detach().numpy()) * 100;\n",
        "        scores_over_time.append(score_now);\n",
        "        print(\"iters: {} , loss: {} , accuracy: {} \\n\".format(iters, loss, score_now));\n",
        "        iters = iters + 1;\n",
        "\n",
        "    with open('/content/drive/My Drive/diffKMeans_out/' + 'cluster_centers.pickle', 'wb') as handle:\n",
        "        pickle.dump(cluster_centers_over_time, handle)\n",
        "\n",
        "    with open('/content/drive/My Drive/diffKMeans_out/' + 'labels_over_time.pickle', 'wb') as handle:\n",
        "        pickle.dump(labels_over_time, handle)\n",
        "\n",
        "    return scores_over_time, labels_over_time, cluster_centers_over_time, loss_vals_over_time;\n",
        "\n",
        "\n",
        "def initializeKMeansPoints(X, K, device):\n",
        "    sx = X.size();\n",
        "    num_s = sx[0];\n",
        "    dim = sx[1];\n",
        "    \n",
        "    U_ret = torch.zeros(K, dim, device=device);\n",
        "    \n",
        "    \n",
        "    distMat = torch.zeros(num_s, K, device=device)\n",
        "\n",
        "\n",
        "    for i in range(K - 1):\n",
        "        if (i == 0):\n",
        "            initInx = torch.rand(1, device=device)*num_s;\n",
        "            initInx.round_();\n",
        "    \n",
        "            firstPoint = X[initInx.long(),:];\n",
        "            U_ret[0,:] = firstPoint;\n",
        "\n",
        "        myP = U_ret[i,:];\n",
        "        \n",
        "        dist = (X - myP) ** 2;\n",
        "        dist = dist.sum(dim=1);\n",
        "        distMat[:,i] = dist;\n",
        "\n",
        "        mVec_o = torch.zeros(num_s, 1, device=device);\n",
        "\n",
        "        for n in range(num_s):\n",
        "            myR = distMat[n,0:i+1];\n",
        "            val = torch.min(myR);\n",
        "            mVec_o[n,0] = val;\n",
        "                  \n",
        "        # j = torch.argmax(mVec_o);\n",
        "        total = torch.sum(mVec_o, dim=0);\n",
        "        frac = mVec_o / total;\n",
        "        pdf = frac.transpose(0,1).cpu().numpy()[0];\n",
        "        inxs = np.array([i for i in range(num_s)]);\n",
        "        j = np.random.choice(inxs, p=pdf);\n",
        "\n",
        "        U_ret[i + 1, :] = X[j,:];\n",
        "    return U_ret;\n",
        "\n",
        "def cluster_acc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate clustering accuracy.\n",
        "    (Taken from https://github.com/XifengGuo/IDEC-toy/blob/master/DEC.py)\n",
        "    # Arguments\n",
        "        y: true labels, numpy.array with shape `(n_samples,)`\n",
        "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
        "    # Return\n",
        "        accuracy, in [0,1]\n",
        "    \"\"\"\n",
        "    y_true = y_true.astype(np.int64)\n",
        "    assert y_pred.size == y_true.size\n",
        "    D = max(y_pred.max(), y_true.max()) + 1\n",
        "    w = np.zeros((D, D), dtype=np.int64)\n",
        "    for i in range(y_pred.size):\n",
        "        w[y_pred[i], y_true[i]] += 1\n",
        "    ind = linear_assignment(w.max() - w) # Optimal label mapping based on the Hungarian algorithm\n",
        "    \n",
        "    return sum(w[ind[0][i], ind[1][i]] for i in range(len(ind[0]))) * 1.0 / y_pred.size\n",
        "\n",
        "\n",
        "with open(file_loc + 'images_reduced.pickle', 'rb') as handle:\n",
        "    images_reduced = pickle.load(handle)\n",
        "\n",
        "with open(file_loc + 'labels_true.pickle', 'rb') as handle:\n",
        "    labels_true = pickle.load(handle)\n",
        "\n",
        "num_epochs = 200;\n",
        "K = 10;\n",
        "learning_rate = 1;\n",
        "\n",
        "print('images reduced size:', images_reduced.size());\n",
        "print(\"\\n\");\n",
        "\n",
        "num_samp = len(images_reduced[:, 0]);\n",
        "num_test = int(num_samp * 0.2);\n",
        "# To save processing time, only run the diff k means on a random 20% of the test set.\n",
        "random.seed(250);\n",
        "test_inxes = [random.randint(0, num_samp) for i in range(num_test)];\n",
        "\n",
        "with open(file_loc + 'test_inxes.pickle', 'wb') as handle:\n",
        "    pickle.dump(test_inxes, handle)\n",
        "\n",
        "#images_test = images_reduced[test_inxes, :];\n",
        "#labels_test = labels_true[test_inxes];\n",
        "images_test = images_reduced;\n",
        "labels_test = labels_true;\n",
        "\n",
        "#Convert the images to a lower dimensional form\n",
        "num_iterations = 1;\n",
        "curIter = 0;\n",
        "BANDWIDTH = 0.2;\n",
        "images_test.detach_();\n",
        "images_test = images_test.to(device0);\n",
        "while (curIter < num_iterations):\n",
        "    scores_over_time, labels_over_time, cluster_centers_over_time, loss_vals_over_time = diffKMeans(images_test, labels_test, K, BANDWIDTH, num_epochs, learning_rate, device0);\n",
        "    print(\"curIter: \\n\", curIter); \n",
        "\n",
        "    epochs = [i for i in range(num_epochs)];\n",
        "\n",
        "    bandw_str = '{}'.format(BANDWIDTH).replace('.', 'p');\n",
        "\n",
        "    f2 = pyplot.figure();\n",
        "    pyplot.scatter(x=epochs, y=loss_vals_over_time, c='k', axes = f2.gca(), marker='o');\n",
        "    path = '{}{}{}{}{}.png'.format(file_loc, 'Losses_BAND_', bandw_str, 'iter', curIter);\n",
        "    pyplot.xlabel('Epochs');\n",
        "    pyplot.ylabel('Loss Vals');\n",
        "    f2.suptitle('Loss values over time - bandwidth : {} , iter: {}'.format(BANDWIDTH, curIter));\n",
        "    f2.savefig(fname=path);\n",
        "\n",
        "    f3 = pyplot.figure();\n",
        "    pyplot.scatter(x=epochs, y=scores_over_time, c='k', axes = f3.gca(), marker='o');\n",
        "    path = '{}{}{}{}{}.png'.format(file_loc, 'ClusterAccuracy_BAND_', BANDWIDTH, 'iter', curIter);\n",
        "    pyplot.xlabel('Epochs');\n",
        "    pyplot.ylabel('Accuracy (%)');\n",
        "    f3.suptitle('Clustering accuracy over time - bandwidth : {} , iter: {}'.format(BANDWIDTH, curIter));\n",
        "    f3.savefig(fname=path);\n",
        "\n",
        "    num_test = int(len(test_inxes) * 0.2);\n",
        "    n_components = 2;\n",
        "    perplexity = 30;\n",
        "    early_exaggeration = 12;\n",
        "    learning_rate = 200;\n",
        "    n_iter = 1000;\n",
        "    n_iter_without_progress = 300;\n",
        "    min_grad_norm = 1e-7;\n",
        "    init='pca';\n",
        "\n",
        "    images_test_clone = images_test.clone().detach_().to('cpu')\n",
        "\n",
        "    myinx = num_epochs - 1;\n",
        "    out_centers = cluster_centers_over_time[myinx,:,:];\n",
        "    out_centers_n = out_centers.clone().detach_().to('cpu');\n",
        "    images_test_clone = torch.cat((images_test_clone, out_centers_n), 0);\n",
        "\n",
        "    tsneOut = TSNE(n_components=n_components, perplexity=perplexity, early_exaggeration=early_exaggeration, \n",
        "               learning_rate=learning_rate, n_iter=n_iter, n_iter_without_progress=n_iter_without_progress, \n",
        "               min_grad_norm=min_grad_norm, init=init).fit_transform(images_test_clone.detach().numpy());\n",
        "\n",
        "    xa = tsneOut[:,0];\n",
        "    ya = tsneOut[:,1];\n",
        "\n",
        "    x_lab = xa[0:num_test];\n",
        "    y_lab = ya[0:num_test];\n",
        "\n",
        "    label_inx = num_test;\n",
        "    label_colors = ['lightcoral', 'moccasin', 'khaki', 'lightgreen', 'paleturquoise', 'dodgerblue', 'blue', 'violet', 'pink', 'lightgrey'];\n",
        "\n",
        "    cluster_colors = 'black';\n",
        "\n",
        "    f4 = pyplot.figure();\n",
        "    f4.suptitle('t-SNE plot - bandwidth: {} , iter {}'.format(BANDWIDTH, curIter));\n",
        "\n",
        "    for itr in range(10):\n",
        "        myColor = label_colors[itr];\n",
        "        myLabel_inxs = [i for i, val in enumerate(labels_test) if val==itr];\n",
        "\n",
        "        x_lab = xa[myLabel_inxs];\n",
        "        y_lab = ya[myLabel_inxs];\n",
        "\n",
        "        pyplot.scatter(x_lab, y_lab, c=myColor, axes=f4.gca(), marker='.');\n",
        "\n",
        "    x_cluster = xa[label_inx:label_inx+K];\n",
        "    y_cluster = ya[label_inx:label_inx+K];\n",
        "\n",
        "    pyplot.scatter(x_cluster, y_cluster, c=cluster_colors, axes=f4.gca(), marker='o', s=72);\n",
        "\n",
        "    path = '{}{}{}{}{}.png'.format(file_loc, 'TSNE_Plot_BANDWIDTH_', bandw_str, '_iter_', curIter);\n",
        "    f4.savefig(fname=path);\n",
        "\n",
        "    curIter = curIter + 1;\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ezDOMfQKn8l"
      },
      "source": [
        "## **Differential K Means Results and Analysis (Part 3/3)**\n",
        "\n",
        "Overall, the algorithm produces a clustering accuracy of about 78% across the entire MNIST dataset.  The optimal bandwidth is about 0.1.  This means that most of the time, the closest cluster cluster to a given point is assigned a probability of 1 on each iteration, and all other cluster centers are assigned a probability of 0.  \n",
        "\n",
        "![ClusterAccuracy_BAND_0.1iter0_10P.png](data:image/png;base64,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)\n",
        "\n",
        "![Losses_BAND_0p1iter0_10P.png](data:image/png;base64,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)\n",
        "\n",
        "I also used t-SNE to plot the data with the chosen cluster centers, but found that method much less useful.\n",
        "\n",
        "\n",
        "In general, performance is bounded by:     \n",
        "\n",
        "1. The imperfect dimensionality reduction performed by the autoencoder, as demonstrated in the t-SNE plot.\n",
        "\n",
        "2.  The fact that k-means assumes that the natural clusters in the data are spherical and non-overlapping, which I highly doubt is the case here.  \n",
        "\n",
        "3.  The performance may be able to be improved by a better autoencoder."
      ]
    }
  ]
}